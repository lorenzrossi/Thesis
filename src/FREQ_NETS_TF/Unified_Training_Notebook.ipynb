{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Unified Energy Forecasting Models\n",
        "\n",
        "This notebook trains and evaluates MLP, LSTM, and CNN models for Italian energy generation forecasting.\n",
        "\n",
        "The models are imported from `models.py` and training is handled by `trainer.py`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from math import sqrt\n",
        "\n",
        "# Setup paths for imports\n",
        "# Get current working directory (should be FREQ_NETS_TF when running notebook)\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Determine notebook directory\n",
        "# If current directory ends with FREQ_NETS_TF, use it; otherwise try to find it\n",
        "if os.path.basename(current_dir) == 'FREQ_NETS_TF':\n",
        "    notebook_dir = current_dir\n",
        "    parent_dir = os.path.dirname(notebook_dir)\n",
        "else:\n",
        "    # Try to find FREQ_NETS_TF in the path\n",
        "    if 'FREQ_NETS_TF' in current_dir:\n",
        "        parts = current_dir.split('FREQ_NETS_TF')\n",
        "        notebook_dir = os.path.join(parts[0], 'FREQ_NETS_TF')\n",
        "        parent_dir = os.path.dirname(notebook_dir)\n",
        "    else:\n",
        "        # Assume we need to go up one level or find src\n",
        "        # This handles cases where notebook is run from project root\n",
        "        notebook_dir = os.path.join(current_dir, 'src', 'FREQ_NETS_TF') if os.path.exists(os.path.join(current_dir, 'src', 'FREQ_NETS_TF')) else current_dir\n",
        "        parent_dir = os.path.dirname(notebook_dir) if os.path.basename(notebook_dir) == 'FREQ_NETS_TF' else notebook_dir\n",
        "\n",
        "# Add paths to sys.path\n",
        "if notebook_dir not in sys.path:\n",
        "    sys.path.insert(0, notebook_dir)\n",
        "if parent_dir not in sys.path:\n",
        "    sys.path.insert(0, parent_dir)\n",
        "\n",
        "# Import from our modules (in same directory as notebook)\n",
        "from models import create_model, ModelBuilder, DEFAULT_CONFIGS\n",
        "from trainer import ModelTrainer, DataPreparator, run_all_models\n",
        "\n",
        "# Import preprocessing functions (from parent directory)\n",
        "from data_preprocessing import preprocess_pipeline, retrieve_data, handle_missing_values, data_and_aggregator, businesshour_and_we_generation\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"✓ Imports successful!\")\n",
        "print(f\"  Current directory: {current_dir}\")\n",
        "print(f\"  Notebook directory: {notebook_dir}\")\n",
        "print(f\"  Parent directory: {parent_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "DATA_PATH = \"data\"  # Change this to your data path\n",
        "DOWNLOAD_FROM_DRIVE = False  # Set to True to download from Google Drive\n",
        "DRIVE_FOLDER_ID = \"1fgXJNVg3MUu8Vx8kAthW4dAih9rKme2H\"  # Google Drive folder ID\n",
        "YEARS = [2016, 2017, 2018, 2019, 2020, 2021]  # Years to load\n",
        "\n",
        "print(\"Loading and preprocessing data...\")\n",
        "\n",
        "# Load and preprocess data\n",
        "if DOWNLOAD_FROM_DRIVE:\n",
        "    data = preprocess_pipeline(\n",
        "        data_path=DATA_PATH,\n",
        "        download_from_drive=True,\n",
        "        drive_folder_id=DRIVE_FOLDER_ID,\n",
        "        years=YEARS\n",
        "    )\n",
        "else:\n",
        "    # Use existing local files\n",
        "    data = retrieve_data(DATA_PATH, years=YEARS)\n",
        "    data = handle_missing_values(data)\n",
        "    data = data_and_aggregator(data)\n",
        "    data = businesshour_and_we_generation(data)\n",
        "    data = data.dropna()\n",
        "\n",
        "print(f\"Data loaded: {data.shape[0]} samples, {data.shape[1]} features\")\n",
        "print(f\"Date range: {data.index.min()} to {data.index.max()}\")\n",
        "print(f\"\\nColumns: {list(data.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Training Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "N_TRAIN = 35064  # 3 years of hourly data (24 * 365 * 3)\n",
        "N_FORECAST_STEPS = 24  # Forecast 24 hours ahead\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 168\n",
        "LEARNING_RATE = 0.003\n",
        "PATIENCE = 3  # Early stopping patience\n",
        "\n",
        "print(f\"Training samples: {N_TRAIN}\")\n",
        "print(f\"Test samples: {len(data) - N_TRAIN}\")\n",
        "print(f\"Forecast horizon: {N_FORECAST_STEPS} hours\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualization Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_predictions_vs_actual(truth, predictions, title=\"Predictions vs Actual\"):\n",
        "    \"\"\"Plot predicted vs actual values.\"\"\"\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.plot(truth, label='Actual', alpha=0.7)\n",
        "    plt.plot(predictions, label='Predicted', color='red', alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Total Aggregated Energy (MW)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. MLP Model Training\n",
        "\n",
        "### 5.1 MLP with Time Series Only\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Training MLP with Time Series Only\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "trainer_mlp_ts = ModelTrainer(\n",
        "    model_type='mlp',\n",
        "    feature_type='ts_only',\n",
        "    window_size=24,  # Use 24 lags\n",
        "    n_forecast_steps=N_FORECAST_STEPS,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    patience=PATIENCE,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "results_mlp_ts = trainer_mlp_ts.train(data, n_train=N_TRAIN, save_model=False)\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"RMSE: {results_mlp_ts['overall_rmse']:.2f}\")\n",
        "print(f\"MAE: {results_mlp_ts['overall_mae']:.2f}\")\n",
        "print(f\"R²: {results_mlp_ts['overall_r2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "plot_predictions_vs_actual(\n",
        "    results_mlp_ts['truth'],\n",
        "    results_mlp_ts['predictions'],\n",
        "    title=\"MLP - Time Series Only: Predictions vs Actual\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 MLP with Weekend Dummies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Training MLP with Weekend Dummies\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "trainer_mlp_we = ModelTrainer(\n",
        "    model_type='mlp',\n",
        "    feature_type='weekend',\n",
        "    window_size=1,  # Use lag_1 with dummies\n",
        "    n_forecast_steps=N_FORECAST_STEPS,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    patience=PATIENCE,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "results_mlp_we = trainer_mlp_we.train(data, n_train=N_TRAIN, save_model=False)\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"RMSE: {results_mlp_we['overall_rmse']:.2f}\")\n",
        "print(f\"MAE: {results_mlp_we['overall_mae']:.2f}\")\n",
        "print(f\"R²: {results_mlp_we['overall_r2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "plot_predictions_vs_actual(\n",
        "    results_mlp_we['truth'],\n",
        "    results_mlp_we['predictions'],\n",
        "    title=\"MLP - Weekend Dummies: Predictions vs Actual\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 MLP with Business Hour Dummy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Training MLP with Business Hour Dummy\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "trainer_mlp_bh = ModelTrainer(\n",
        "    model_type='mlp',\n",
        "    feature_type='business_hour',\n",
        "    window_size=1,  # Use lag_1 with dummy\n",
        "    n_forecast_steps=N_FORECAST_STEPS,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    patience=PATIENCE,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "results_mlp_bh = trainer_mlp_bh.train(data, n_train=N_TRAIN, save_model=False)\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"RMSE: {results_mlp_bh['overall_rmse']:.2f}\")\n",
        "print(f\"MAE: {results_mlp_bh['overall_mae']:.2f}\")\n",
        "print(f\"R²: {results_mlp_bh['overall_r2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "plot_predictions_vs_actual(\n",
        "    results_mlp_bh['truth'],\n",
        "    results_mlp_bh['predictions'],\n",
        "    title=\"MLP - Business Hour: Predictions vs Actual\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. LSTM Model Training\n",
        "\n",
        "### 6.1 LSTM with Time Series Only\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Training LSTM with Time Series Only\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "trainer_lstm_ts = ModelTrainer(\n",
        "    model_type='lstm',\n",
        "    feature_type='ts_only',\n",
        "    window_size=1,  # Sequence length of 1\n",
        "    n_forecast_steps=N_FORECAST_STEPS,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    patience=PATIENCE,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "results_lstm_ts = trainer_lstm_ts.train(data, n_train=N_TRAIN, save_model=False)\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"RMSE: {results_lstm_ts['overall_rmse']:.2f}\")\n",
        "print(f\"MAE: {results_lstm_ts['overall_mae']:.2f}\")\n",
        "print(f\"R²: {results_lstm_ts['overall_r2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "plot_predictions_vs_actual(\n",
        "    results_lstm_ts['truth'],\n",
        "    results_lstm_ts['predictions'],\n",
        "    title=\"LSTM - Time Series Only: Predictions vs Actual\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 LSTM with Weekend Dummies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Training LSTM with Weekend Dummies\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "trainer_lstm_we = ModelTrainer(\n",
        "    model_type='lstm',\n",
        "    feature_type='weekend',\n",
        "    window_size=1,\n",
        "    n_forecast_steps=N_FORECAST_STEPS,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    patience=PATIENCE,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "results_lstm_we = trainer_lstm_we.train(data, n_train=N_TRAIN, save_model=False)\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"RMSE: {results_lstm_we['overall_rmse']:.2f}\")\n",
        "print(f\"MAE: {results_lstm_we['overall_mae']:.2f}\")\n",
        "print(f\"R²: {results_lstm_we['overall_r2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "plot_predictions_vs_actual(\n",
        "    results_lstm_we['truth'],\n",
        "    results_lstm_we['predictions'],\n",
        "    title=\"LSTM - Weekend Dummies: Predictions vs Actual\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 LSTM with Business Hour Dummy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Training LSTM with Business Hour Dummy\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "trainer_lstm_bh = ModelTrainer(\n",
        "    model_type='lstm',\n",
        "    feature_type='business_hour',\n",
        "    window_size=1,\n",
        "    n_forecast_steps=N_FORECAST_STEPS,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    patience=PATIENCE,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "results_lstm_bh = trainer_lstm_bh.train(data, n_train=N_TRAIN, save_model=False)\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"RMSE: {results_lstm_bh['overall_rmse']:.2f}\")\n",
        "print(f\"MAE: {results_lstm_bh['overall_mae']:.2f}\")\n",
        "print(f\"R²: {results_lstm_bh['overall_r2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "plot_predictions_vs_actual(\n",
        "    results_lstm_bh['truth'],\n",
        "    results_lstm_bh['predictions'],\n",
        "    title=\"LSTM - Business Hour: Predictions vs Actual\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. CNN Model Training\n",
        "\n",
        "### 7.1 CNN with Time Series Only\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Training CNN with Time Series Only\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "trainer_cnn_ts = ModelTrainer(\n",
        "    model_type='cnn',\n",
        "    feature_type='ts_only',\n",
        "    window_size=2,  # Window of 2 timesteps\n",
        "    n_forecast_steps=N_FORECAST_STEPS,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    patience=PATIENCE,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "results_cnn_ts = trainer_cnn_ts.train(data, n_train=N_TRAIN, save_model=False)\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"RMSE: {results_cnn_ts['overall_rmse']:.2f}\")\n",
        "print(f\"MAE: {results_cnn_ts['overall_mae']:.2f}\")\n",
        "print(f\"R²: {results_cnn_ts['overall_r2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "plot_predictions_vs_actual(\n",
        "    results_cnn_ts['truth'],\n",
        "    results_cnn_ts['predictions'],\n",
        "    title=\"CNN - Time Series Only: Predictions vs Actual\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 CNN with Weekend Dummies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Training CNN with Weekend Dummies\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "trainer_cnn_we = ModelTrainer(\n",
        "    model_type='cnn',\n",
        "    feature_type='weekend',\n",
        "    window_size=2,\n",
        "    n_forecast_steps=N_FORECAST_STEPS,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    patience=PATIENCE,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "results_cnn_we = trainer_cnn_we.train(data, n_train=N_TRAIN, save_model=False)\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"RMSE: {results_cnn_we['overall_rmse']:.2f}\")\n",
        "print(f\"MAE: {results_cnn_we['overall_mae']:.2f}\")\n",
        "print(f\"R²: {results_cnn_we['overall_r2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "plot_predictions_vs_actual(\n",
        "    results_cnn_we['truth'],\n",
        "    results_cnn_we['predictions'],\n",
        "    title=\"CNN - Weekend Dummies: Predictions vs Actual\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.3 CNN with Business Hour Dummy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Training CNN with Business Hour Dummy\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "trainer_cnn_bh = ModelTrainer(\n",
        "    model_type='cnn',\n",
        "    feature_type='business_hour',\n",
        "    window_size=2,\n",
        "    n_forecast_steps=N_FORECAST_STEPS,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    patience=PATIENCE,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "results_cnn_bh = trainer_cnn_bh.train(data, n_train=N_TRAIN, save_model=False)\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"RMSE: {results_cnn_bh['overall_rmse']:.2f}\")\n",
        "print(f\"MAE: {results_cnn_bh['overall_mae']:.2f}\")\n",
        "print(f\"R²: {results_cnn_bh['overall_r2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "plot_predictions_vs_actual(\n",
        "    results_cnn_bh['truth'],\n",
        "    results_cnn_bh['predictions'],\n",
        "    title=\"CNN - Business Hour: Predictions vs Actual\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Results Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all results\n",
        "all_results = [\n",
        "    {'Model': 'MLP', 'Features': 'TS Only', 'RMSE': results_mlp_ts['overall_rmse'], \n",
        "     'MAE': results_mlp_ts['overall_mae'], 'R²': results_mlp_ts['overall_r2']},\n",
        "    {'Model': 'MLP', 'Features': 'Weekend', 'RMSE': results_mlp_we['overall_rmse'], \n",
        "     'MAE': results_mlp_we['overall_mae'], 'R²': results_mlp_we['overall_r2']},\n",
        "    {'Model': 'MLP', 'Features': 'Business Hour', 'RMSE': results_mlp_bh['overall_rmse'], \n",
        "     'MAE': results_mlp_bh['overall_mae'], 'R²': results_mlp_bh['overall_r2']},\n",
        "    {'Model': 'LSTM', 'Features': 'TS Only', 'RMSE': results_lstm_ts['overall_rmse'], \n",
        "     'MAE': results_lstm_ts['overall_mae'], 'R²': results_lstm_ts['overall_r2']},\n",
        "    {'Model': 'LSTM', 'Features': 'Weekend', 'RMSE': results_lstm_we['overall_rmse'], \n",
        "     'MAE': results_lstm_we['overall_mae'], 'R²': results_lstm_we['overall_r2']},\n",
        "    {'Model': 'LSTM', 'Features': 'Business Hour', 'RMSE': results_lstm_bh['overall_rmse'], \n",
        "     'MAE': results_lstm_bh['overall_mae'], 'R²': results_lstm_bh['overall_r2']},\n",
        "    {'Model': 'CNN', 'Features': 'TS Only', 'RMSE': results_cnn_ts['overall_rmse'], \n",
        "     'MAE': results_cnn_ts['overall_mae'], 'R²': results_cnn_ts['overall_r2']},\n",
        "    {'Model': 'CNN', 'Features': 'Weekend', 'RMSE': results_cnn_we['overall_rmse'], \n",
        "     'MAE': results_cnn_we['overall_mae'], 'R²': results_cnn_we['overall_r2']},\n",
        "    {'Model': 'CNN', 'Features': 'Business Hour', 'RMSE': results_cnn_bh['overall_rmse'], \n",
        "     'MAE': results_cnn_bh['overall_mae'], 'R²': results_cnn_bh['overall_r2']},\n",
        "]\n",
        "\n",
        "results_df = pd.DataFrame(all_results)\n",
        "results_df = results_df.sort_values('RMSE')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ALL MODELS COMPARISON (Sorted by RMSE)\")\n",
        "print(\"=\"*60)\n",
        "print(results_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# RMSE comparison\n",
        "results_pivot_rmse = results_df.pivot(index='Model', columns='Features', values='RMSE')\n",
        "results_pivot_rmse.plot(kind='bar', ax=axes[0], color=['skyblue', 'lightcoral', 'lightgreen'])\n",
        "axes[0].set_title('RMSE Comparison by Model')\n",
        "axes[0].set_ylabel('RMSE')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "axes[0].legend(title='Features')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# MAE comparison\n",
        "results_pivot_mae = results_df.pivot(index='Model', columns='Features', values='MAE')\n",
        "results_pivot_mae.plot(kind='bar', ax=axes[1], color=['skyblue', 'lightcoral', 'lightgreen'])\n",
        "axes[1].set_title('MAE Comparison by Model')\n",
        "axes[1].set_ylabel('MAE')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "axes[1].legend(title='Features')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# R² comparison\n",
        "results_pivot_r2 = results_df.pivot(index='Model', columns='Features', values='R²')\n",
        "results_pivot_r2.plot(kind='bar', ax=axes[2], color=['skyblue', 'lightcoral', 'lightgreen'])\n",
        "axes[2].set_title('R² Comparison by Model')\n",
        "axes[2].set_ylabel('R²')\n",
        "axes[2].tick_params(axis='x', rotation=45)\n",
        "axes[2].legend(title='Features')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Best model\n",
        "best_model = results_df.iloc[0]\n",
        "print(\"=\"*60)\n",
        "print(\"BEST MODEL\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Model: {best_model['Model']}\")\n",
        "print(f\"Features: {best_model['Features']}\")\n",
        "print(f\"RMSE: {best_model['RMSE']:.2f}\")\n",
        "print(f\"MAE: {best_model['MAE']:.2f}\")\n",
        "print(f\"R²: {best_model['R²']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Optional: Run All Models Automatically\n",
        "\n",
        "Alternatively, you can use the `run_all_models()` function to automatically run all configurations:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative: Use the run_all_models function for automatic execution\n",
        "# Uncomment to use:\n",
        "\n",
        "# results_df_auto = run_all_models(\n",
        "#     data_path=DATA_PATH,\n",
        "#     download_from_drive=DOWNLOAD_FROM_DRIVE,\n",
        "#     drive_folder_id=DRIVE_FOLDER_ID,\n",
        "#     years=YEARS,\n",
        "#     n_train=N_TRAIN,\n",
        "#     save_results=True,\n",
        "#     results_path=\"results\"\n",
        "# )\n",
        "# \n",
        "# print(results_df_auto)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
